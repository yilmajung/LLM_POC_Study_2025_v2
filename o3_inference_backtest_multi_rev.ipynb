{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# n3_inference_backtest_multi.ipynb\n",
    "Inference + backtesting for multiple subgroup schemes.\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "CS_PATH=\"data/GSS/gss_abt_cs_full.csv\"; OUT_DIR=\"outputs_gss_multitask\"\n",
    "CANON4=[\"strong_anti\",\"anti\",\"pro\",\"strong_pro\"]; K=len(CANON4)\n",
    "GROUP_SCHEMES={\"GROUP_COLS_1\":[\"gender\"],\n",
    "               \"GROUP_COLS_2\":[\"gender\",\"political_views\"],\n",
    "               \"GROUP_COLS_3\":[\"gender\",\"political_views\",\"edu_level\"],\n",
    "               \"GROUP_COLS_4\":[\"gender\",\"political_views\",\"edu_level\",\"generation\"],\n",
    "               \"GROUP_COLS_5\":[\"gender\",\"political_views\",\"edu_level\",\"generation\",\"race\"]}\n",
    "CURRENT_GROUP_SCHEME=\"GROUP_COLS_3\"\n",
    "def get_group_cols(): return GROUP_SCHEMES[CURRENT_GROUP_SCHEME]\n",
    "print(\"Active grouping:\", get_group_cols())\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os, json, numpy as np, pandas as pd, torch, torch.nn as nn\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "SAVE_DIR=os.path.join(OUT_DIR,f\"final_{CURRENT_GROUP_SCHEME}\")\n",
    "LM_DIR=os.path.join(SAVE_DIR,\"lora\"); HEAD_PATH=os.path.join(SAVE_DIR,\"two_head.pt\")\n",
    "tokenizer=AutoTokenizer.from_pretrained(LM_DIR)\n",
    "base=AutoModelForCausalLM.from_pretrained(LM_DIR, device_map=\"auto\"); model=base\n",
    "hidden_size=base.config.hidden_size\n",
    "class TwoHead(nn.Module):\n",
    "    def __init__(self,H,K): super().__init__(); self.trans=nn.Linear(H,K); self.margin=nn.Linear(H,K)\n",
    "    def forward(self,z): return self.trans(z), self.margin(z)\n",
    "two_head=TwoHead(hidden_size, K).to(next(base.parameters()).device)\n",
    "two_head.load_state_dict(torch.load(HEAD_PATH, map_location=\"cpu\")); two_head=two_head.to(next(base.parameters()).device).eval()\n",
    "print(\"Loaded:\", SAVE_DIR)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def span_indices(text, tokenizer):\n",
    "    gpos=text.find(\"Group:\")\n",
    "    if gpos<0:\n",
    "        enc=tokenizer(text, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "        L=int(enc[\"input_ids\"].shape[1]); return 0, max(1, L-1)\n",
    "    end=text.find(\"\\n\", gpos); end=len(text) if end<0 else end\n",
    "    enc_pre=tokenizer(text[:gpos], return_tensors=\"pt\"); enc_end=tokenizer(text[:end], return_tensors=\"pt\")\n",
    "    return int(enc_pre[\"input_ids\"].shape[1]), int(enc_end[\"input_ids\"].shape[1])\n",
    "\n",
    "def pooled_vec(prompt):\n",
    "    enc=tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=1024)\n",
    "    enc={k:v.to(model.device) for k,v in enc.items()}\n",
    "    with torch.no_grad():\n",
    "        out=model(**enc, output_hidden_states=True); hs=out.hidden_states[-1]\n",
    "        s,e=span_indices(prompt, tokenizer); s=max(0,min(s,hs.shape[1]-1)); e=max(s+1,min(e,hs.shape[1]))\n",
    "        return hs[:, s:e, :].mean(dim=1)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def predict_full_transition(meta, year_t, year_t1):\n",
    "    rows=[]\n",
    "    for from_bin in CANON4:\n",
    "        prompt=(\"[Task: Predict transition row]\\n\"\n",
    "                f\"From: <Y{year_t}> \u2192 To: <Y{year_t1}> <DT{year_t1-year_t}>\\n\"\n",
    "                \"Group: \"+\"; \".join(f\"{k}={v}\" for k,v in meta.items())+\"\\n\"\n",
    "                f\"From option: {from_bin}\\n\"\n",
    "                \"Answer:\\n\")\n",
    "        z=pooled_vec(prompt)\n",
    "        with torch.no_grad():\n",
    "            lr,_=two_head(z); p=torch.softmax(lr, dim=1).cpu().numpy()[0]\n",
    "        rows.append(p)\n",
    "    T=np.vstack(rows); T=T/np.clip(T.sum(axis=1, keepdims=True), 1e-12, None)\n",
    "    return T\n",
    "\n",
    "def predict_next_margin(meta, context_list, target_year):\n",
    "    ctx_str=\" \".join([f\"<Y{yy}>[\"+\",\".join(f\"{x:.4f}\" for x in p)+\"]\" for yy,p in context_list])\n",
    "    prompt=(\"[Task: Forecast next-wave margin]\\n\"\n",
    "            \"Group: \"+\"; \".join(f\"{k}={v}\" for k,v in meta.items())+\"\\n\"\n",
    "            f\"Context: {ctx_str}\\n\"\n",
    "            f\"Predict: <Y{target_year}>\\n\"\n",
    "            \"Answer:\\n\")\n",
    "    z=pooled_vec(prompt)\n",
    "    with torch.no_grad():\n",
    "        _,lm=two_head(z); p=torch.softmax(lm, dim=1).cpu().numpy()[0]\n",
    "    return p/np.clip(p.sum(), 1e-12, None)\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def load_cs_margins(path, group_cols):\n",
    "    df=pd.read_csv(path)\n",
    "    if \"id\" in df.columns: df.rename(columns={\"id\":\"yearid\"}, inplace=True)\n",
    "    df[\"att_id\"]=df[\"abortion_att4\"].astype(int)\n",
    "    out={}; effN={}\n",
    "    for (keys,gdf) in df.groupby(group_cols+[\"year\"], dropna=False):\n",
    "        *g_vals, y = keys\n",
    "        w=gdf[\"wtssps\"].fillna(0.0).to_numpy(float); k=gdf[\"att_id\"].to_numpy(int)\n",
    "        vec=np.zeros(K)\n",
    "        for ki,wi in zip(k,w):\n",
    "            if 1<=ki<=4: vec[ki-1]+=wi\n",
    "        tot=vec.sum()\n",
    "        if tot<=0: continue\n",
    "        out[(tuple(g_vals), int(y))]=vec/tot\n",
    "        sw=w.sum(); sw2=(w**2).sum(); eff=(sw**2/sw2) if sw2>0 else len(w)\n",
    "        effN[(tuple(g_vals), int(y))]=float(eff)\n",
    "    return out, effN\n",
    "\n",
    "p_cs, effN_cs = load_cs_margins(CS_PATH, get_group_cols())\n",
    "print(\"Loaded CS margins:\", len(p_cs))\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def forecast_every_year_from_previous(p_cs, alpha=0.5, context_lags=(4,2,0)):\n",
    "    rows=[]; by_group={}\n",
    "    for (g,y), _ in p_cs.items():\n",
    "        by_group.setdefault(g, []).append(y)\n",
    "    for g, ys in by_group.items():\n",
    "        ys=sorted(ys)\n",
    "        for i in range(1,len(ys)):\n",
    "            y_prev, y = ys[i-1], ys[i]\n",
    "            meta = {c:v for c,v in zip(get_group_cols(), g)}\n",
    "            p_prev = p_cs[(g, y_prev)]\n",
    "            T = predict_full_transition(meta, y_prev, y)\n",
    "            p_trans = p_prev @ T\n",
    "            ctx=[]\n",
    "            for L in context_lags:\n",
    "                yy = y_prev - L\n",
    "                if (g, yy) in p_cs: ctx.append((yy, p_cs[(g, yy)]))\n",
    "            if not ctx: ctx=[(y_prev, p_prev)]\n",
    "            p_margin = predict_next_margin(meta, ctx, y)\n",
    "            p_hat = alpha*p_trans + (1-alpha)*p_margin\n",
    "            p_hat = p_hat/np.clip(p_hat.sum(), 1e-12, None)\n",
    "\n",
    "            p_obs = p_cs.get((g, y))\n",
    "            def jsd(a,b,eps=1e-12):\n",
    "                import numpy as np\n",
    "                a=np.clip(a,eps,1); b=np.clip(b,eps,1); a/=a.sum(); b/=b.sum(); m=0.5*(a+b)\n",
    "                return 0.5*np.sum(a*np.log(a/m)) + 0.5*np.sum(b*np.log(b/m))\n",
    "            rec={c:v for c,v in zip(get_group_cols(), g)}\n",
    "            rec.update({\"year_t\":y_prev,\"year_t1\":y,\n",
    "                        **{f\"p_prev_{CANON4[i]}\":float(p_prev[i]) for i in range(K)},\n",
    "                        **{f\"p_trans_{CANON4[i]}\":float(p_trans[i]) for i in range(K)},\n",
    "                        **{f\"p_margin_{CANON4[i]}\":float(p_margin[i]) for i in range(K)},\n",
    "                        **{f\"p_hat_{CANON4[i]}\":float(p_hat[i]) for i in range(K)}})\n",
    "            if p_obs is not None:\n",
    "                rec.update({f\"p_obs_{CANON4[i]}\":float(p_obs[i]) for i in range(K)})\n",
    "                rec[\"JSD_hat\"]=float(jsd(p_hat, p_obs)); rec[\"JSD_trans\"]=float(jsd(p_trans, p_obs)); rec[\"JSD_margin\"]=float(jsd(p_margin, p_obs))\n",
    "            rows.append(rec)\n",
    "    import pandas as pd\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "bt = forecast_every_year_from_previous(p_cs, alpha=0.5)\n",
    "BT_PATH = os.path.join(OUT_DIR, f\"backtest_{CURRENT_GROUP_SCHEME}.csv\")\n",
    "bt.to_csv(BT_PATH, index=False)\n",
    "print(\"Backtest saved:\", BT_PATH)\n",
    "bt.head(3)\n"
   ],
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}