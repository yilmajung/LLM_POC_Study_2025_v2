{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8f8ca13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb3783f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y6/z9h695vx2w3gbjh7z32h4j9m0000gn/T/ipykernel_17527/1045978283.py:2: UnicodeWarning: \n",
      "One or more strings in the dta file could not be decoded using utf-8, and\n",
      "so the fallback encoding of latin-1 is being used.  This can happen when a file\n",
      "has been incorrectly encoded by Stata or some other software. You should verify\n",
      "the string values returned are correct.\n",
      "  gss_2020 = pd.read_stata('Data/GSS/GSS_panel2020_r1a.dta', convert_categoricals=False)\n"
     ]
    }
   ],
   "source": [
    "# Load Stata .dta file and convert to CSV\n",
    "gss_2020 = pd.read_stata('Data/GSS/GSS_panel2020_r1a.dta', convert_categoricals=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2e3a63b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>samptype</th>\n",
       "      <th>yearid</th>\n",
       "      <th>fileversion</th>\n",
       "      <th>panstat</th>\n",
       "      <th>wtssall_1a</th>\n",
       "      <th>wtssall_1b</th>\n",
       "      <th>wtssall_2</th>\n",
       "      <th>wtssnr_1a</th>\n",
       "      <th>wtssnr_1b</th>\n",
       "      <th>wtssnr_2</th>\n",
       "      <th>...</th>\n",
       "      <th>sprtlrgr_2</th>\n",
       "      <th>sprtpurp_2</th>\n",
       "      <th>poltrtblk_2</th>\n",
       "      <th>poltrthsp_2</th>\n",
       "      <th>defund_2</th>\n",
       "      <th>strvbias_2</th>\n",
       "      <th>wrycovid_2</th>\n",
       "      <th>wrypaybills_2</th>\n",
       "      <th>wrygetsick_2</th>\n",
       "      <th>anesid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2016</td>\n",
       "      <td>20160001</td>\n",
       "      <td>GSS 2020 Panel Release 1 (May 2021)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.956994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.085009</td>\n",
       "      <td>1.260478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.443929</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>169657.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2016</td>\n",
       "      <td>20160002</td>\n",
       "      <td>GSS 2020 Panel Release 1 (May 2021)</td>\n",
       "      <td>1</td>\n",
       "      <td>0.478497</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.542504</td>\n",
       "      <td>0.630239</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.721964</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>169664.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2016</td>\n",
       "      <td>20160003</td>\n",
       "      <td>GSS 2020 Panel Release 1 (May 2021)</td>\n",
       "      <td>0</td>\n",
       "      <td>0.956994</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.260478</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2016</td>\n",
       "      <td>20160004</td>\n",
       "      <td>GSS 2020 Panel Release 1 (May 2021)</td>\n",
       "      <td>1</td>\n",
       "      <td>1.913987</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.170018</td>\n",
       "      <td>2.520956</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.887858</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2016</td>\n",
       "      <td>20160005</td>\n",
       "      <td>GSS 2020 Panel Release 1 (May 2021)</td>\n",
       "      <td>0</td>\n",
       "      <td>1.435490</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.890717</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 4296 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   samptype    yearid                          fileversion  panstat  \\\n",
       "0      2016  20160001  GSS 2020 Panel Release 1 (May 2021)        1   \n",
       "1      2016  20160002  GSS 2020 Panel Release 1 (May 2021)        1   \n",
       "2      2016  20160003  GSS 2020 Panel Release 1 (May 2021)        0   \n",
       "3      2016  20160004  GSS 2020 Panel Release 1 (May 2021)        1   \n",
       "4      2016  20160005  GSS 2020 Panel Release 1 (May 2021)        0   \n",
       "\n",
       "   wtssall_1a  wtssall_1b  wtssall_2  wtssnr_1a  wtssnr_1b  wtssnr_2  ...  \\\n",
       "0    0.956994         NaN   1.085009   1.260478        NaN  1.443929  ...   \n",
       "1    0.478497         NaN   0.542504   0.630239        NaN  0.721964  ...   \n",
       "2    0.956994         NaN        NaN   1.260478        NaN       NaN  ...   \n",
       "3    1.913987         NaN   2.170018   2.520956        NaN  2.887858  ...   \n",
       "4    1.435490         NaN        NaN   1.890717        NaN       NaN  ...   \n",
       "\n",
       "   sprtlrgr_2  sprtpurp_2  poltrtblk_2  poltrthsp_2  defund_2  strvbias_2  \\\n",
       "0         7.0         7.0          2.0          4.0       2.0         2.0   \n",
       "1         7.0         7.0          4.0          4.0       1.0         2.0   \n",
       "2         NaN         NaN          NaN          NaN       NaN         NaN   \n",
       "3         5.0         4.0          4.0          4.0       2.0         1.0   \n",
       "4         NaN         NaN          NaN          NaN       NaN         NaN   \n",
       "\n",
       "   wrycovid_2  wrypaybills_2  wrygetsick_2    anesid  \n",
       "0         3.0            4.0           3.0  169657.0  \n",
       "1         4.0            4.0           3.0  169664.0  \n",
       "2         NaN            NaN           NaN       NaN  \n",
       "3         3.0            4.0           4.0       NaN  \n",
       "4         NaN            NaN           NaN       NaN  \n",
       "\n",
       "[5 rows x 4296 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gss_2020.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "acbbd7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expect one row per respondent per wave, columns listed below:\n",
    "BINARY_ITEMS_2016 = [\"abdefect_1a\",\"abnomore_1a\",\"abany_1a\",\"abhlth_1a\",\"abpoor_1a\",\"abrape_1a\",\"absingle_1a\"]\n",
    "BINARY_ITEMS_2018 = [\"abdefect_1b\",\"abnomore_1b\",\"abany_1b\",\"abhlth_1b\",\"abpoor_1b\",\"abrape_1b\",\"absingle_1b\"]\n",
    "BINARY_ITEMS_2020 = [\"abdefect_2\",\"abnomore_2\",\"abany_2\",\"abhlth_2\",\"abpoor_2\",\"abrape_2\",\"absingle_2\"]\n",
    "\n",
    "# Map raw responses → 1/0 (edit as needed to match your GSS coding)\n",
    "YES_VALUES = {\"yes\",\"Yes\",\"YES\",1, \"1\", True}\n",
    "NO_VALUES  = {\"no\",\"No\",\"NO\",2, \"2\", False}\n",
    "\n",
    "def to_binary(s):\n",
    "    if pd.isna(s): return np.nan\n",
    "    return 1 if s in YES_VALUES else (0 if s in NO_VALUES else np.nan)\n",
    "\n",
    "def prepare_binary_2016(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for col in BINARY_ITEMS_2016:\n",
    "        if col in out.columns:\n",
    "            out[col+\"_bin\"] = out[col].apply(to_binary).astype(\"float\")\n",
    "    return out\n",
    "\n",
    "def prepare_binary_2018(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for col in BINARY_ITEMS_2018:\n",
    "        if col in out.columns:\n",
    "            out[col+\"_bin\"] = out[col].apply(to_binary).astype(\"float\")\n",
    "    return out\n",
    "\n",
    "def prepare_binary_2020(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for col in BINARY_ITEMS_2020:\n",
    "        if col in out.columns:\n",
    "            out[col+\"_bin\"] = out[col].apply(to_binary).astype(\"float\")\n",
    "    return out\n",
    "\n",
    "def collapse_abortion_attitudes(df: pd.DataFrame, id_col=\"yearid\", wave_col=\"samptype\", binary_items=None):\n",
    "    \"\"\"\n",
    "    Collapse 7 binary GSS abortion items into a single 5-level categorical variable.\n",
    "    \n",
    "    - Input: df with columns abdefect ... absingle coded 0/1 (NaN allowed).\n",
    "    - Output: df with new columns:\n",
    "        'n_yes'  (count of yes across 7 items)\n",
    "        'att5'   (collapsed attitude category)\n",
    "    \"\"\"\n",
    "    out = df.copy()\n",
    "\n",
    "    # Count number of \"yes\" responses (ignore NaN)\n",
    "    out[\"n_yes\"] = out[binary_items].sum(axis=1, skipna=True)\n",
    "\n",
    "    # Map counts into categories\n",
    "    def map_to_cat(n_yes):\n",
    "        if pd.isna(n_yes):\n",
    "            return np.nan\n",
    "        n_yes = int(n_yes)\n",
    "        if n_yes <= 1:\n",
    "            return \"strong_anti\"\n",
    "        elif n_yes <= 3:\n",
    "            return \"anti\"\n",
    "        elif n_yes == 4:\n",
    "            return \"neutral\"\n",
    "        elif n_yes <= 6:\n",
    "            return \"pro\"\n",
    "        else:  # n_yes == 7\n",
    "            return \"strong_pro\"\n",
    "\n",
    "    out[\"att5\"] = out[\"n_yes\"].apply(map_to_cat)\n",
    "\n",
    "    return out[[id_col, wave_col, \"n_yes\", \"att5\"]]\n",
    "\n",
    "# def composite_score_binary(gss_bin: pd.DataFrame, id_col=\"yearid\", wave_col=\"samptype\"):\n",
    "#     # compute per-row mean of available items\n",
    "#     item_cols = [c for c in gss_bin.columns if c.endswith(\"_bin\")]\n",
    "#     df = gss_bin[[id_col, wave_col] + item_cols].copy()\n",
    "#     df[\"prop_yes\"] = df[item_cols].mean(axis=1, skipna=True)\n",
    "#     # z-score within wave to stabilize across waves\n",
    "#     df[\"prop_yes_z\"] = df.groupby(wave_col)[\"prop_yes\"].transform(lambda s: (s - s.mean())/(s.std(ddof=0)+1e-8))\n",
    "#     return df[[id_col, wave_col, \"prop_yes_z\"]]\n",
    "\n",
    "# def bin_prop_to_5(df_prop: pd.DataFrame, wave_col=\"samptype\"):\n",
    "#     # quantile bins by wave\n",
    "#     out = df_prop.copy()\n",
    "#     labels = [\"strong_anti\",\"anti\",\"neutral\",\"pro\",\"strong_pro\"]\n",
    "#     out[\"att5\"] = np.nan\n",
    "#     for w, g in out.groupby(wave_col):\n",
    "#         q = g[\"prop_yes_z\"].quantile([0.1,0.3,0.7,0.9]).tolist()\n",
    "#         def f(x):\n",
    "#             if pd.isna(x): return np.nan\n",
    "#             if x <= q[0]: return \"strong_anti\"\n",
    "#             if x <= q[1]: return \"anti\"\n",
    "#             if x <= q[2]: return \"neutral\"\n",
    "#             if x <= q[3]: return \"pro\"\n",
    "#             return \"strong_pro\"\n",
    "#         out.loc[g.index, \"att5\"] = g[\"prop_yes_z\"].apply(f)\n",
    "#     return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "624dd223",
   "metadata": {},
   "outputs": [],
   "source": [
    "gss_2016 = gss_2020[gss_2020['samptype'] == 2016]\n",
    "gss_2018 = gss_2020[gss_2020['samptype'] == 2018]\n",
    "\n",
    "gss_2016_bin = prepare_binary_2016(gss_2016)\n",
    "gss_2018_bin = prepare_binary_2018(gss_2018)\n",
    "gss_2020_bin = prepare_binary_2020(gss_2020)\n",
    "\n",
    "gss_2016_bin = collapse_abortion_attitudes(gss_2016_bin, wave_col=\"samptype\", binary_items=[col+\"_bin\" for col in BINARY_ITEMS_2016])\n",
    "gss_2018_bin = collapse_abortion_attitudes(gss_2018_bin, wave_col=\"samptype\", binary_items=[col+\"_bin\" for col in BINARY_ITEMS_2018])\n",
    "gss_2020_bin = collapse_abortion_attitudes(gss_2020_bin, wave_col=\"samptype\", binary_items=[col+\"_bin\" for col in BINARY_ITEMS_2020])\n",
    "\n",
    "# gss_2016_bin = composite_score_binary(gss_2016_bin)\n",
    "# gss_2018_bin = composite_score_binary(gss_2018_bin)\n",
    "# gss_2020_bin = composite_score_binary(gss_2020_bin)\n",
    "\n",
    "# gss_2016_bin = bin_prop_to_5(gss_2016_bin)\n",
    "# gss_2018_bin = bin_prop_to_5(gss_2018_bin)\n",
    "# gss_2020_bin = bin_prop_to_5(gss_2020_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28767923",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2867, 4)\n",
      "(2348, 4)\n",
      "(5215, 4)\n"
     ]
    }
   ],
   "source": [
    "# Rename columns for clarity\n",
    "gss_2016_bin = gss_2016_bin.rename(columns={\"n_yes\":\"n_yes_2016\", \"att5\":\"att5_2016\"})\n",
    "gss_2018_bin = gss_2018_bin.rename(columns={\"n_yes\":\"n_yes_2018\", \"att5\":\"att5_2018\"})\n",
    "gss_2020_bin = gss_2020_bin.rename(columns={\"n_yes\":\"n_yes_2020\", \"att5\":\"att5_2020\"})\n",
    "\n",
    "print(gss_2016_bin.shape)\n",
    "print(gss_2018_bin.shape)\n",
    "print(gss_2020_bin.shape)\n",
    "\n",
    "# Merge all years into one DataFrame\n",
    "gss_panel_2016 = gss_2016_bin.merge(gss_2020_bin, on=\"yearid\", how=\"left\")\n",
    "gss_panel_2018 = gss_2018_bin.merge(gss_2020_bin, on=\"yearid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a40ffea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Required columns (demographic) from gss_2020\n",
    "required_columns_2016 = [\"cohort_1a\", \"degree_1a\", \"race_1a\", \"gender1_1a\"]\n",
    "required_columns_2018 = [\"cohort_1b\", \"degree_1b\", \"race_1b\", \"gender1_1b\"]\n",
    "\n",
    "# Merge demographic columns\n",
    "gss_panel_2016 = gss_panel_2016.merge(gss_2020[required_columns_2016 + [\"yearid\"]], on=\"yearid\", how=\"left\")\n",
    "gss_panel_2018 = gss_panel_2018.merge(gss_2020[required_columns_2018 + [\"yearid\"]], on=\"yearid\", how=\"left\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38ee6466",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>yearid</th>\n",
       "      <th>samptype_x</th>\n",
       "      <th>n_yes_2016</th>\n",
       "      <th>att5_2016</th>\n",
       "      <th>samptype_y</th>\n",
       "      <th>n_yes_2020</th>\n",
       "      <th>att5_2020</th>\n",
       "      <th>cohort_1a</th>\n",
       "      <th>degree_1a</th>\n",
       "      <th>race_1a</th>\n",
       "      <th>gender1_1a</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160001</td>\n",
       "      <td>2016</td>\n",
       "      <td>7.0</td>\n",
       "      <td>strong_pro</td>\n",
       "      <td>2016</td>\n",
       "      <td>7.0</td>\n",
       "      <td>strong_pro</td>\n",
       "      <td>1969.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160002</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>strong_anti</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>strong_anti</td>\n",
       "      <td>1955.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160003</td>\n",
       "      <td>2016</td>\n",
       "      <td>2.0</td>\n",
       "      <td>anti</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>strong_anti</td>\n",
       "      <td>1944.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160004</td>\n",
       "      <td>2016</td>\n",
       "      <td>2.0</td>\n",
       "      <td>anti</td>\n",
       "      <td>2016</td>\n",
       "      <td>2.0</td>\n",
       "      <td>anti</td>\n",
       "      <td>1973.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160005</td>\n",
       "      <td>2016</td>\n",
       "      <td>7.0</td>\n",
       "      <td>strong_pro</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.0</td>\n",
       "      <td>strong_anti</td>\n",
       "      <td>1961.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     yearid  samptype_x  n_yes_2016    att5_2016  samptype_y  n_yes_2020  \\\n",
       "0  20160001        2016         7.0   strong_pro        2016         7.0   \n",
       "1  20160002        2016         0.0  strong_anti        2016         0.0   \n",
       "2  20160003        2016         2.0         anti        2016         0.0   \n",
       "3  20160004        2016         2.0         anti        2016         2.0   \n",
       "4  20160005        2016         7.0   strong_pro        2016         0.0   \n",
       "\n",
       "     att5_2020  cohort_1a  degree_1a  race_1a  gender1_1a  \n",
       "0   strong_pro     1969.0        3.0      1.0         1.0  \n",
       "1  strong_anti     1955.0        1.0      1.0         1.0  \n",
       "2  strong_anti     1944.0        3.0      1.0         1.0  \n",
       "3         anti     1973.0        1.0      1.0         1.0  \n",
       "4  strong_anti     1961.0        4.0      1.0         1.0  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gss_panel_2016.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a2bd20af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create generation column based on birth year\n",
    "def determine_generation(year):\n",
    "    if pd.isna(year):\n",
    "        return None\n",
    "    year = int(year)\n",
    "    if year <= 1945:\n",
    "        return \"Silent Generation\"\n",
    "    elif 1946 <= year <= 1964:\n",
    "        return \"Baby Boomer\"\n",
    "    elif 1965 <= year <= 1980:\n",
    "        return \"Generation X\"\n",
    "    elif 1981 <= year <= 1996:\n",
    "        return \"Millennial\"\n",
    "    elif 1997 <= year <= 2012:\n",
    "        return \"Generation Z\"\n",
    "    else:\n",
    "        return \"Generation Alpha\"\n",
    "\n",
    "gss_panel_2016['generation'] = gss_panel_2016['cohort_1a'].apply(determine_generation)\n",
    "gss_panel_2018['generation'] = gss_panel_2018['cohort_1b'].apply(determine_generation)\n",
    "\n",
    "# Create education level column\n",
    "def categorize_education(edu):\n",
    "    if pd.isna(edu):\n",
    "        return None\n",
    "    elif edu == 0:\n",
    "        return \"Less than High School\"\n",
    "    elif edu == 1 or edu == 2:\n",
    "        return \"High School to Associate Degree\"\n",
    "    elif edu == 3:\n",
    "        return \"Bachelor's Degree\"\n",
    "    elif edu == 4:\n",
    "        return \"Graduate Degree\"\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "gss_panel_2016['edu_level'] = gss_panel_2016['degree_1a'].apply(categorize_education)\n",
    "gss_panel_2018['edu_level'] = gss_panel_2018['degree_1b'].apply(categorize_education)\n",
    "\n",
    "# Create gender column\n",
    "def categorize_gender(gender):\n",
    "    if pd.isna(gender):\n",
    "        return None\n",
    "    elif gender == 1:\n",
    "        return \"Male\"\n",
    "    elif gender == 2:\n",
    "        return \"Female\"\n",
    "    else:\n",
    "        return \"Other\"\n",
    "\n",
    "gss_panel_2016['gender'] = gss_panel_2016['gender1_1a'].apply(categorize_gender)\n",
    "gss_panel_2018['gender'] = gss_panel_2018['gender1_1b'].apply(categorize_gender)\n",
    "\n",
    "# Create race column\n",
    "def categorize_race(race):\n",
    "    if pd.isna(race):\n",
    "        return None\n",
    "    elif race == 1:\n",
    "        return \"White\"\n",
    "    elif race == 2:\n",
    "        return \"Black\"\n",
    "    elif race == 3:\n",
    "        return \"Other\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "\n",
    "gss_panel_2016['race'] = gss_panel_2016['race_1a'].apply(categorize_race)\n",
    "gss_panel_2018['race'] = gss_panel_2018['race_1b'].apply(categorize_race)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "211fa0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter out unnecessary columns\n",
    "gss_panel_2016 = gss_panel_2016[[\"yearid\", \"att5_2016\", \"att5_2020\", \"generation\", \"edu_level\", \"gender\", \"race\"]]\n",
    "gss_panel_2018 = gss_panel_2018[[\"yearid\", \"att5_2018\", \"att5_2020\", \"generation\", \"edu_level\", \"gender\", \"race\"]]\n",
    "\n",
    "# Convert to long format for analysis\n",
    "gss_panel_2016_long = pd.melt(gss_panel_2016, id_vars=[\"yearid\", \"generation\", \"edu_level\", \"gender\", \"race\"], var_name=\"year\", value_name=\"att5\")\n",
    "gss_panel_2018_long = pd.melt(gss_panel_2018, id_vars=[\"yearid\", \"generation\", \"edu_level\", \"gender\", \"race\"], var_name=\"year\", value_name=\"att5\")\n",
    "\n",
    "# Remove \"att5_\" from the year column\n",
    "gss_panel_2016_long[\"year\"] = gss_panel_2016_long[\"year\"].str.replace(\"att5_\", \"\")\n",
    "gss_panel_2018_long[\"year\"] = gss_panel_2018_long[\"year\"].str.replace(\"att5_\", \"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "916e16e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to CSV\n",
    "gss_panel_2016_long.to_csv(\"data/GSS/gss_panel_2016_long.csv\", index=False)\n",
    "gss_panel_2018_long.to_csv(\"data/GSS/gss_panel_2018_long.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdf5f1e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm_poc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
